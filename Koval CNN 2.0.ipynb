{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Import Libraries:\n",
    "from __future__ import print_function\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random\n",
    "import math\n",
    "import time\n",
    "import joblib\n",
    "import shutil\n",
    "from shutil import copyfile\n",
    "import os\n",
    "\n",
    "import keras\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Activation, Flatten\n",
    "from keras.layers import Convolution2D, MaxPooling2D\n",
    "from keras.layers import Dense, GlobalAveragePooling2D\n",
    "from keras.optimizers import adam\n",
    "from keras.models import Model\n",
    "from keras.applications.vgg19 import VGG19\n",
    "from keras.applications.inception_v3 import InceptionV3\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Variables and Paths - Need To Be Customized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Global variables\n",
    "all_image_dir = 'C:\\\\Users\\\\Aadi\\\\Documents\\\\GitHub\\\\KovalCNN\\\\all_images\\\\' #This is the directory with all images (128x128 etc) in it\n",
    "temp_image_dir = 'C:\\\\Users\\\\Aadi\\\\Documents\\\\GitHub\\\\KovalCNN\\\\tmp_images\\\\' #this is the directory where images will be stored during training\n",
    "img_history_dir = 'C:\\\\Users\\\\Aadi\\\\Documents\\\\GitHub\\\\KovalCNN\\\\image_history\\\\' #this is where we will keep records about image partitions for previous training rounds\n",
    "csv_path = 'C:\\\\Users\\\\Aadi\\\\Documents\\\\GitHub\\\\KovalCNN\\\\all_images\\\\data.csv' #this is the csv with all of the metadata for the images\n",
    "class_variable_in_data_csv = 'benign_malignant' #the variable name in the csv where the above class names are found\n",
    "filename_col_name_in_csv = 'filename'\n",
    "useFilter = True\n",
    "pandas_filter_string = \"data_filtered = data\" #pandas string to be used for filtering e.g. data_filtered = data[data['age'] == 'young']\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Supporting functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#if not os.path.exists(temp_image_dir):\n",
    "#    os.makedirs(temp_image_dir)\n",
    "\n",
    "def create_directories(image_dir, class_names):\n",
    "    shutil.rmtree(image_dir)\n",
    "    if not os.path.exists(temp_image_dir):\n",
    "        os.makedirs(temp_image_dir)\n",
    "    train_dir = temp_image_dir+'train\\\\'\n",
    "    test_dir = temp_image_dir+'test\\\\'\n",
    "    train_test = ['train', 'val']\n",
    "    for dir_a in train_test:\n",
    "        directory1 = image_dir + dir_a + '\\\\'\n",
    "        if not os.path.exists(directory1):\n",
    "            os.makedirs(directory1)\n",
    "        for dir_b in class_names:\n",
    "            directory2 = image_dir + dir_a + '\\\\' + dir_b + '\\\\'\n",
    "            if not os.path.exists(directory2):\n",
    "                os.makedirs(directory2)\n",
    "    \n",
    "def copyfile_(data, i, dst_dir, src_dir):\n",
    "    filename = data.iloc[i][filename_col_name_in_csv]\n",
    "    print(filename, i)\n",
    "    copyfile(src=src_dir+filename, dst=dst_dir+filename)\n",
    "\n",
    "def split_data(data, class_names, id_var, var_name, train_prop = 0.8):\n",
    "    train_test = ['train', 'val']\n",
    "    train_df=data.sample(frac=train_prop,random_state=200)\n",
    "    val_df=data.drop(train_df.index)\n",
    "    train_df.to_csv(img_history_dir+'train_images_'+str(id_var)+'.csv')\n",
    "    val_df.to_csv(img_history_dir+'val_images_'+str(id_var)+'.csv')\n",
    "    for dir_a in train_test:\n",
    "        for class_ in class_names:\n",
    "            directory = temp_image_dir + dir_a + '\\\\' + class_ + '\\\\'\n",
    "            if dir_a == 'train':\n",
    "                df = train_df\n",
    "            else:\n",
    "                df = val_df\n",
    "            df_ = df[df[var_name]==class_]\n",
    "            df_ = df_.reset_index(drop=True)\n",
    "            joblib.Parallel(n_jobs=8)(joblib.delayed(copyfile_)(df_, i, directory, all_image_dir) for i in range(0, df_.shape[0]))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Architecture and Training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ignore the actual accuracy results below. I just used made up data. But we can see that the code works"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "importing data\n",
      "creating directories\n",
      "partitioning data\n",
      "Downloading data from https://github.com/fchollet/deep-learning-models/releases/download/v0.5/inception_v3_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
      "87916544/87910968 [==============================] - 7s 0us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Aadi\\Anaconda3\\lib\\site-packages\\ipykernel\\__main__.py:34: UserWarning: Update your `Model` call to the Keras 2 API: `Model(outputs=Tensor(\"de..., inputs=Tensor(\"in...)`\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 891 images belonging to 2 classes.\n",
      "Found 223 images belonging to 2 classes.\n",
      "Epoch 1/100\n",
      "25/25 [==============================] - 12s 492ms/step - loss: 1.7266 - acc: 0.2800 - val_loss: 1.6661 - val_acc: 0.4400\n",
      "Epoch 2/100\n",
      "25/25 [==============================] - 3s 118ms/step - loss: 0.7667 - acc: 0.4000 - val_loss: 0.6680 - val_acc: 0.6000\n",
      "Epoch 3/100\n",
      "25/25 [==============================] - 3s 119ms/step - loss: 0.9153 - acc: 0.5200 - val_loss: 0.7344 - val_acc: 0.6000\n",
      "Epoch 4/100\n",
      "25/25 [==============================] - 3s 121ms/step - loss: 0.7303 - acc: 0.4800 - val_loss: 0.6760 - val_acc: 0.5600\n",
      "Epoch 5/100\n",
      "25/25 [==============================] - 3s 121ms/step - loss: 0.7206 - acc: 0.5200 - val_loss: 0.7296 - val_acc: 0.5200\n",
      "Epoch 6/100\n",
      "25/25 [==============================] - 3s 120ms/step - loss: 0.8156 - acc: 0.5200 - val_loss: 0.6737 - val_acc: 0.5600\n",
      "Epoch 7/100\n",
      "25/25 [==============================] - 3s 120ms/step - loss: 0.7236 - acc: 0.5200 - val_loss: 0.7005 - val_acc: 0.5200\n",
      "Epoch 8/100\n",
      "24/25 [===========================>..] - ETA: 0s - loss: 0.7137 - acc: 0.2917"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-23-87354c5d081d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     66\u001b[0m             \u001b[0mepochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m100\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m     67\u001b[0m             \u001b[0mvalidation_data\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mvalidation_generator\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m---> 68\u001b[0;31m             validation_steps=validationsamples/batchsize)\n\u001b[0m\u001b[1;32m     69\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m     70\u001b[0m     \u001b[0mhist\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mhistory\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mC:\\Users\\Aadi\\Anaconda3\\lib\\site-packages\\keras\\legacy\\interfaces.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     89\u001b[0m                 warnings.warn('Update your `' + object_name +\n\u001b[1;32m     90\u001b[0m                               '` call to the Keras 2 API: ' + signature, stacklevel=2)\n\u001b[0;32m---> 91\u001b[0;31m             \u001b[1;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     92\u001b[0m         \u001b[0mwrapper\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_original_function\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m     93\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mC:\\Users\\Aadi\\Anaconda3\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit_generator\u001b[0;34m(self, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[1;32m   1424\u001b[0m             \u001b[0muse_multiprocessing\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0muse_multiprocessing\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m   1425\u001b[0m             \u001b[0mshuffle\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1426\u001b[0;31m             initial_epoch=initial_epoch)\n\u001b[0m\u001b[1;32m   1427\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m   1428\u001b[0m     \u001b[1;33m@\u001b[0m\u001b[0minterfaces\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlegacy_generator_methods_support\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mC:\\Users\\Aadi\\Anaconda3\\lib\\site-packages\\keras\\engine\\training_generator.py\u001b[0m in \u001b[0;36mfit_generator\u001b[0;34m(model, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[1;32m    189\u001b[0m                 outs = model.train_on_batch(x, y,\n\u001b[1;32m    190\u001b[0m                                             \u001b[0msample_weight\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m--> 191\u001b[0;31m                                             class_weight=class_weight)\n\u001b[0m\u001b[1;32m    192\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    193\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mC:\\Users\\Aadi\\Anaconda3\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mtrain_on_batch\u001b[0;34m(self, x, y, sample_weight, class_weight)\u001b[0m\n\u001b[1;32m   1218\u001b[0m             \u001b[0mins\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mx\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0my\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0msample_weights\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m   1219\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_make_train_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1220\u001b[0;31m         \u001b[0moutputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mins\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1221\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m   1222\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0moutputs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mC:\\Users\\Aadi\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2659\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_legacy_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m   2660\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2661\u001b[0;31m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2662\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m   2663\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mpy_any\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mis_tensor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[1;32min\u001b[0m \u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mC:\\Users\\Aadi\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2629\u001b[0m                                 \u001b[0msymbol_vals\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m   2630\u001b[0m                                 session)\n\u001b[0;32m-> 2631\u001b[0;31m         \u001b[0mfetched\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2632\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mfetched\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m   2633\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mC:\\Users\\Aadi\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m   1449\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_created_with_new_api\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m   1450\u001b[0m           return tf_session.TF_SessionRunCallable(\n\u001b[0;32m-> 1451\u001b[0;31m               self._session._session, self._handle, args, status, None)\n\u001b[0m\u001b[1;32m   1452\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m   1453\u001b[0m           return tf_session.TF_DeprecatedSessionRunCallable(\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "\n",
    "if __name__ == '__main__':\n",
    "    id_var = math.floor(time.time())\n",
    "    colormode = 'rgb'\n",
    "    channels = 3 #color images have 3 channels. grayscale images have 1 channel\n",
    "    batchsize = 1 #Number of images to be used in each processing batch. Larger batches have a greater impact on training accuracy but that isn't always a good thing\n",
    "    trainingsamples = 25 #Number of images to be used for training set\n",
    "    validationsamples = 25 #Number of images to be used for validation set\n",
    "    model_name = 'KovalModel_'+str(id_var) #Any name for saving and keeping track of this model\n",
    "    data_filtered = ''\n",
    "    \n",
    "    print('importing data')\n",
    "    data = pd.read_csv(csv_path)\n",
    "    if useFilter is True:\n",
    "        exec(pandas_filter_string)\n",
    "    class_names = data_filtered[class_variable_in_data_csv].unique() #class names of interest\n",
    "    numclasses = len(class_names)\n",
    "    print('creating directories')\n",
    "    create_directories(temp_image_dir, class_names)\n",
    "    print ('partitioning data')\n",
    "    split_data(data_filtered, class_names, id_var, class_variable_in_data_csv)\n",
    "    \n",
    "        \n",
    "    # create the base pre-trained model\n",
    "    base_model = InceptionV3(weights='imagenet', include_top=False)\n",
    "\n",
    "    # add a global spatial average pooling layer\n",
    "    x = base_model.output\n",
    "    x = GlobalAveragePooling2D()(x)\n",
    "    # let's add a fully-connected layer\n",
    "    x = Dense(1024, activation='relu')(x)\n",
    "    # and a logistic layer\n",
    "    predictions = Dense(numclasses, activation='softmax')(x)\n",
    "\n",
    "    # this is the model we will train\n",
    "    model = Model(input=base_model.input, output=predictions)\n",
    "\n",
    "    # first: train only the top layers (which were randomly initialized)\n",
    "    # i.e. freeze all convolutional InceptionV3 layers\n",
    "    for layer in base_model.layers:\n",
    "        layer.trainable = True\n",
    "\n",
    "    for layer in model.layers:\n",
    "        layer.trainable = True\n",
    "    # compile the model (should be done *after* setting layers to non-trainable)\n",
    "    model.compile(optimizer='adam', loss='binary_crossentropy',  metrics=['accuracy']) #create model with for binary output with the adam optimization algorithm\n",
    "    \n",
    "    train_datagen = ImageDataGenerator(horizontal_flip=True, vertical_flip=True) # use ImageDataGenerator to enhance the size of our dataset by randomly flipping images. There are many more transformations that are possible\n",
    "    test_datagen = ImageDataGenerator()\n",
    "\n",
    "#the following code reads images, trains the model, and saves the training history to a csv file:\n",
    "\n",
    "    train_generator = train_datagen.flow_from_directory(\n",
    "            temp_image_dir+\"train\",\n",
    "            target_size=(150, 150),\n",
    "            batch_size=batchsize,\n",
    "            color_mode=colormode)\n",
    "\n",
    "    validation_generator = test_datagen.flow_from_directory(\n",
    "            temp_image_dir+\"val\",\n",
    "            target_size=(150, 150),\n",
    "            batch_size=batchsize,\n",
    "            color_mode=colormode)\n",
    "\n",
    "    history = model.fit_generator(\n",
    "            train_generator,\n",
    "            steps_per_epoch=trainingsamples/batchsize,\n",
    "            epochs=100,\n",
    "            validation_data=validation_generator,\n",
    "            validation_steps=validationsamples/batchsize)\n",
    "\n",
    "    hist = history.history\n",
    "    hist = pd.DataFrame(hist)\n",
    "    hist.to_csv(root_dir+'results\\\\'+model_name+'.csv')\n",
    "    model.save(root_dir+'models\\\\'+model_name+'.h5')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
