{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "#Import Libraries:\n",
    "from __future__ import print_function\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random\n",
    "import math\n",
    "import time\n",
    "import joblib\n",
    "import shutil\n",
    "from shutil import copyfile\n",
    "import os\n",
    "\n",
    "import keras\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Activation, Flatten\n",
    "from keras.layers import Convolution2D, MaxPooling2D\n",
    "from keras.layers import Dense, GlobalAveragePooling2D\n",
    "from keras.optimizers import adam\n",
    "from keras.models import Model\n",
    "from keras.applications.vgg19 import VGG19\n",
    "from keras.applications.inception_v3 import InceptionV3\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Variables and Paths - Need To Be Customized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Global variables\n",
    "all_image_dir = 'C:\\\\Users\\\\Aadi\\\\Documents\\\\GitHub\\\\KovalCNN\\\\all_images\\\\' #This is the directory with all images (128x128 etc) in it\n",
    "temp_image_dir = 'C:\\\\Users\\\\Aadi\\\\Documents\\\\GitHub\\\\KovalCNN\\\\tmp_images\\\\' #this is the directory where images will be stored during training\n",
    "img_history_dir = 'C:\\\\Users\\\\Aadi\\\\Documents\\\\GitHub\\\\KovalCNN\\\\image_history\\\\' #this is where we will keep records about image partitions for previous training rounds\n",
    "csv_path = 'C:\\\\Users\\\\Aadi\\\\Documents\\\\GitHub\\\\KovalCNN\\\\all_images\\\\data.csv' #this is the csv with all of the metadata for the images\n",
    "class_variable_in_data_csv = 'benign_malignant' #the variable name in the csv where the above class names are found\n",
    "filename_col_name_in_csv = 'filename'\n",
    "useFilter = True\n",
    "pandas_filter_string = \"data_filtered = data\" #pandas string to be used for filtering e.g. data_filtered = data[data['age'] == 'young']\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Supporting functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#if not os.path.exists(temp_image_dir):\n",
    "#    os.makedirs(temp_image_dir)\n",
    "\n",
    "def create_directories(image_dir, class_names):\n",
    "    shutil.rmtree(image_dir)\n",
    "    if not os.path.exists(temp_image_dir):\n",
    "        os.makedirs(temp_image_dir)\n",
    "    train_dir = temp_image_dir+'train\\\\'\n",
    "    test_dir = temp_image_dir+'test\\\\'\n",
    "    train_test = ['train', 'val']\n",
    "    for dir_a in train_test:\n",
    "        directory1 = image_dir + dir_a + '\\\\'\n",
    "        if not os.path.exists(directory1):\n",
    "            os.makedirs(directory1)\n",
    "        for dir_b in class_names:\n",
    "            directory2 = image_dir + dir_a + '\\\\' + dir_b + '\\\\'\n",
    "            if not os.path.exists(directory2):\n",
    "                os.makedirs(directory2)\n",
    "    \n",
    "def copyfile_(data, i, dst_dir, src_dir):\n",
    "    filename = data.iloc[i][filename_col_name_in_csv]\n",
    "    print(filename, i)\n",
    "    copyfile(src=src_dir+filename, dst=dst_dir+filename)\n",
    "\n",
    "def split_data(data, class_names, id_var, var_name, train_prop = 0.8):\n",
    "    train_test = ['train', 'val']\n",
    "    train_df=data.sample(frac=train_prop,random_state=200)\n",
    "    val_df=data.drop(train_df.index)\n",
    "    train_df.to_csv(img_history_dir+'train_images_'+str(id_var)+'.csv')\n",
    "    val_df.to_csv(img_history_dir+'val_images_'+str(id_var)+'.csv')\n",
    "    for dir_a in train_test:\n",
    "        for class_ in class_names:\n",
    "            directory = temp_image_dir + dir_a + '\\\\' + class_ + '\\\\'\n",
    "            if dir_a == 'train':\n",
    "                df = train_df\n",
    "            else:\n",
    "                df = val_df\n",
    "            df_ = df[df[var_name]==class_]\n",
    "            df_ = df_.reset_index(drop=True)\n",
    "            joblib.Parallel(n_jobs=8)(joblib.delayed(copyfile_)(df_, i, directory, all_image_dir) for i in range(0, df_.shape[0]))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Architecture and Training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ignore the actual accuracy results below. I just used made up data. But we can see that the code works"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "importing data\n",
      "creating directories\n",
      "partitioning data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Aadi\\Anaconda3\\lib\\site-packages\\ipykernel\\__main__.py:36: UserWarning: Update your `Model` call to the Keras 2 API: `Model(outputs=Tensor(\"de..., inputs=Tensor(\"in...)`\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 1797 images belonging to 2 classes.\n",
      "Found 449 images belonging to 2 classes.\n",
      "Epoch 1/100\n",
      "25/25 [==============================] - 14s 548ms/step - loss: 8.3567 - acc: 0.4800 - val_loss: 7.6945 - val_acc: 0.5200\n",
      "Epoch 2/100\n",
      "25/25 [==============================] - 3s 121ms/step - loss: 9.6181 - acc: 0.4000 - val_loss: 7.6945 - val_acc: 0.5200\n",
      "Epoch 3/100\n",
      "25/25 [==============================] - 3s 125ms/step - loss: 5.1297 - acc: 0.6800 - val_loss: 7.6945 - val_acc: 0.5200\n",
      "Epoch 4/100\n",
      "25/25 [==============================] - 3s 124ms/step - loss: 8.3357 - acc: 0.4800 - val_loss: 7.6945 - val_acc: 0.5200\n",
      "Epoch 5/100\n",
      "25/25 [==============================] - 3s 126ms/step - loss: 8.3357 - acc: 0.4800 - val_loss: 7.6945 - val_acc: 0.5200\n",
      "Epoch 6/100\n",
      "25/25 [==============================] - 3s 124ms/step - loss: 12.1830 - acc: 0.2400 - val_loss: 7.6945 - val_acc: 0.5200\n",
      "Epoch 7/100\n",
      "25/25 [==============================] - 3s 124ms/step - loss: 6.4121 - acc: 0.6000 - val_loss: 7.6945 - val_acc: 0.5200\n",
      "Epoch 8/100\n",
      "25/25 [==============================] - 3s 126ms/step - loss: 10.9006 - acc: 0.3200 - val_loss: 7.6945 - val_acc: 0.5200\n",
      "Epoch 9/100\n",
      "25/25 [==============================] - 3s 123ms/step - loss: 7.0533 - acc: 0.5600 - val_loss: 7.6945 - val_acc: 0.5200\n",
      "Epoch 10/100\n",
      "25/25 [==============================] - 3s 120ms/step - loss: 7.6945 - acc: 0.5200 - val_loss: 7.6945 - val_acc: 0.5200\n",
      "Epoch 11/100\n",
      "25/25 [==============================] - 3s 122ms/step - loss: 7.6945 - acc: 0.5200 - val_loss: 7.6945 - val_acc: 0.5200\n",
      "Epoch 12/100\n",
      "25/25 [==============================] - 3s 123ms/step - loss: 8.9769 - acc: 0.4400 - val_loss: 7.6945 - val_acc: 0.5200\n",
      "Epoch 13/100\n",
      "25/25 [==============================] - 3s 124ms/step - loss: 8.3357 - acc: 0.4800 - val_loss: 7.6945 - val_acc: 0.5200\n",
      "Epoch 14/100\n",
      "25/25 [==============================] - 3s 124ms/step - loss: 10.9006 - acc: 0.3200 - val_loss: 7.6945 - val_acc: 0.5200\n",
      "Epoch 15/100\n",
      "25/25 [==============================] - 3s 123ms/step - loss: 6.4121 - acc: 0.6000 - val_loss: 7.6945 - val_acc: 0.5200\n",
      "Epoch 16/100\n",
      "25/25 [==============================] - 3s 123ms/step - loss: 5.7709 - acc: 0.6400 - val_loss: 7.6945 - val_acc: 0.5200\n",
      "Epoch 17/100\n",
      "25/25 [==============================] - 3s 125ms/step - loss: 7.6945 - acc: 0.5200 - val_loss: 7.6945 - val_acc: 0.5200\n",
      "Epoch 18/100\n",
      "25/25 [==============================] - 3s 121ms/step - loss: 8.9769 - acc: 0.4400 - val_loss: 7.6945 - val_acc: 0.5200\n",
      "Epoch 19/100\n",
      "16/25 [==================>...........] - ETA: 0s - loss: 7.0132 - acc: 0.5625"
     ]
    }
   ],
   "source": [
    "\n",
    "if __name__ == '__main__':\n",
    "    id_var = math.floor(time.time())\n",
    "    colormode = 'rgb'\n",
    "    channels = 3 #color images have 3 channels. grayscale images have 1 channel\n",
    "    batchsize = 1 #Number of images to be used in each processing batch. Larger batches have a greater impact on training accuracy but that isn't always a good thing\n",
    "    trainingsamples = 25 #Number of images to be used for training set\n",
    "    validationsamples = 25 #Number of images to be used for validation set\n",
    "    model_name = 'KovalModel_'+str(id_var) #Any name for saving and keeping track of this model\n",
    "    data_filtered = ''\n",
    "    \n",
    "    print('importing data')\n",
    "    data = pd.read_csv(csv_path)\n",
    "    if useFilter is True:\n",
    "        exec(pandas_filter_string)\n",
    "    class_names = data_filtered[class_variable_in_data_csv].unique() #class names of interest\n",
    "    numclasses = len(class_names)\n",
    "    print('creating directories')\n",
    "    create_directories(temp_image_dir, class_names)\n",
    "    print ('partitioning data')\n",
    "    split_data(data_filtered, class_names, id_var, class_variable_in_data_csv)\n",
    "    \n",
    "        \n",
    "    # create the base pre-trained model\n",
    "    base_model = InceptionV3(weights='imagenet', include_top=False)\n",
    "\n",
    "    # add a global spatial average pooling layer\n",
    "    x = base_model.output\n",
    "    x = GlobalAveragePooling2D()(x)\n",
    "    # let's add a fully-connected layer\n",
    "    x = Dense(1024, activation='relu')(x)\n",
    "    # and a logistic layer\n",
    "    predictions = Dense(numclasses, activation='softmax')(x)\n",
    "\n",
    "    # this is the model we will train\n",
    "    model = Model(input=base_model.input, output=predictions)\n",
    "\n",
    "    # first: train only the top layers (which were randomly initialized)\n",
    "    # i.e. freeze all convolutional InceptionV3 layers\n",
    "    for layer in base_model.layers:\n",
    "        layer.trainable = True\n",
    "\n",
    "    for layer in model.layers:\n",
    "        layer.trainable = True\n",
    "    # compile the model (should be done *after* setting layers to non-trainable)\n",
    "    model.compile(optimizer='adam', loss='binary_crossentropy',  metrics=['accuracy']) #create model with for binary output with the adam optimization algorithm\n",
    "    \n",
    "    train_datagen = ImageDataGenerator(horizontal_flip=True, vertical_flip=True) # use ImageDataGenerator to enhance the size of our dataset by randomly flipping images. There are many more transformations that are possible\n",
    "    test_datagen = ImageDataGenerator()\n",
    "\n",
    "#the following code reads images, trains the model, and saves the training history to a csv file:\n",
    "\n",
    "    train_generator = train_datagen.flow_from_directory(\n",
    "            temp_image_dir+\"train\",\n",
    "            target_size=(150, 150),\n",
    "            batch_size=batchsize,\n",
    "            color_mode=colormode)\n",
    "\n",
    "    validation_generator = test_datagen.flow_from_directory(\n",
    "            temp_image_dir+\"val\",\n",
    "            target_size=(150, 150),\n",
    "            batch_size=batchsize,\n",
    "            color_mode=colormode)\n",
    "\n",
    "    history = model.fit_generator(\n",
    "            train_generator,\n",
    "            steps_per_epoch=trainingsamples/batchsize,\n",
    "            epochs=100,\n",
    "            validation_data=validation_generator,\n",
    "            validation_steps=validationsamples/batchsize)\n",
    "\n",
    "    hist = history.history\n",
    "    hist = pd.DataFrame(hist)\n",
    "    hist.to_csv(root_dir+'results\\\\'+model_name+'.csv')\n",
    "    model.save(root_dir+'models\\\\'+model_name+'.h5')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
